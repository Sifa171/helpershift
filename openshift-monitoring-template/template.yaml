apiVersion: v1
kind: Template
metadata:
  creationTimestamp: null
  name: openshift-monitoring-template
objects:
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
    creationTimestamp: null
    generation: 1
    labels:
      app: node-exporter
    name: node-exporter
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: node-exporter
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: node-exporter
      spec:
        containers:
        - args:
          - --web.listen-address=127.0.0.1:9101
          - --path.procfs=/host/proc
          - --path.sysfs=/host/sys
          - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
          - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
          - --no-collector.wifi
          image: openshift/prometheus-node-exporter:v0.16.0
          imagePullPolicy: IfNotPresent
          name: node-exporter
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /host/proc
            name: proc
          - mountPath: /host/sys
            name: sys
          - mountPath: /host/root
            mountPropagation: HostToContainer
            name: root
            readOnly: true
        - args:
          - --secure-listen-address=:9100
          - --upstream=http://127.0.0.1:9101/
          - --tls-cert-file=/etc/tls/private/tls.crt
          - --tls-private-key-file=/etc/tls/private/tls.key
          image: quay.io/coreos/kube-rbac-proxy:v0.3.1
          imagePullPolicy: IfNotPresent
          name: kube-rbac-proxy
          ports:
          - containerPort: 9100
            hostPort: 9100
            name: https
            protocol: TCP
          resources:
            limits:
              cpu: 20m
              memory: 40Mi
            requests:
              cpu: 10m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/tls/private
            name: node-exporter-tls
        dnsPolicy: ClusterFirst
        hostNetwork: true
        hostPID: true
        nodeSelector:
          beta.kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: node-exporter
        serviceAccountName: node-exporter
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        volumes:
        - hostPath:
            path: /proc
            type: ""
          name: proc
        - hostPath:
            path: /sys
            type: ""
          name: sys
        - hostPath:
            path: /
            type: ""
          name: root
        - name: node-exporter-tls
          secret:
            defaultMode: 420
            secretName: node-exporter-tls
    updateStrategy:
      rollingUpdate:
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 11
    desiredNumberScheduled: 11
    numberAvailable: 11
    numberMisscheduled: 0
    numberReady: 11
    observedGeneration: 1
    updatedNumberScheduled: 11
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: null
    generation: 1
    labels:
      app: cluster-monitoring-operator
    name: cluster-monitoring-operator
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: cluster-monitoring-operator
    strategy:
      rollingUpdate:
        maxSurge: 1
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: cluster-monitoring-operator
      spec:
        containers:
        - args:
          - -namespace=openshift-monitoring
          - -configmap=cluster-monitoring-config
          - -logtostderr=true
          - -v=4
          image: quay.io/coreos/cluster-monitoring-operator:v0.1.1
          imagePullPolicy: IfNotPresent
          name: cluster-monitoring-operator
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          resources:
            limits:
              cpu: 20m
              memory: 50Mi
            requests:
              cpu: 20m
              memory: 50Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          node-role.kubernetes.io/infra: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: cluster-monitoring-operator
        serviceAccountName: cluster-monitoring-operator
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: 2018-11-02T10:40:43Z
      lastUpdateTime: 2018-11-02T10:40:43Z
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: 2018-11-02T10:40:43Z
      lastUpdateTime: 2018-11-02T10:41:00Z
      message: ReplicaSet "cluster-monitoring-operator-6465f8fbc7" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: null
    generation: 1706
    labels:
      app: grafana
    name: grafana
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: grafana
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: grafana
      spec:
        containers:
        - args:
          - -config=/etc/grafana/grafana.ini
          image: grafana/grafana:5.2.1
          imagePullPolicy: IfNotPresent
          name: grafana
          ports:
          - containerPort: 3000
            name: http
            protocol: TCP
          resources:
            limits:
              cpu: 200m
              memory: 200Mi
            requests:
              cpu: 100m
              memory: 100Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/grafana
            name: grafana-storage
          - mountPath: /etc/grafana/provisioning/datasources
            name: grafana-datasources
          - mountPath: /etc/grafana/provisioning/dashboards
            name: grafana-dashboards
          - mountPath: /grafana-dashboard-definitions/0/k8s-cluster-rsrc-use
            name: grafana-dashboard-k8s-cluster-rsrc-use
          - mountPath: /grafana-dashboard-definitions/0/k8s-node-rsrc-use
            name: grafana-dashboard-k8s-node-rsrc-use
          - mountPath: /grafana-dashboard-definitions/0/k8s-resources-cluster
            name: grafana-dashboard-k8s-resources-cluster
          - mountPath: /grafana-dashboard-definitions/0/k8s-resources-namespace
            name: grafana-dashboard-k8s-resources-namespace
          - mountPath: /grafana-dashboard-definitions/0/k8s-resources-pod
            name: grafana-dashboard-k8s-resources-pod
          - mountPath: /etc/grafana
            name: grafana-config
        - args:
          - -provider=openshift
          - -https-address=:3000
          - -http-address=
          - -email-domain=*
          - -upstream=http://localhost:3001
          - '-openshift-sar={"resource": "namespaces", "verb": "get"}'
          - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get"}}'
          - -tls-cert=/etc/tls/private/tls.crt
          - -tls-key=/etc/tls/private/tls.key
          - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
          - -cookie-secret-file=/etc/proxy/secrets/session_secret
          - -openshift-service-account=grafana
          - -openshift-ca=/etc/pki/tls/cert.pem
          - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          - -skip-auth-regex=^/metrics
          image: openshift/oauth-proxy:v1.1.0
          imagePullPolicy: IfNotPresent
          name: grafana-proxy
          ports:
          - containerPort: 3000
            name: https
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/tls/private
            name: secret-grafana-tls
          - mountPath: /etc/proxy/secrets
            name: secret-grafana-proxy
        dnsPolicy: ClusterFirst
        nodeSelector:
          node-role.kubernetes.io/infra: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: grafana
        serviceAccountName: grafana
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: grafana-storage
        - name: grafana-datasources
          secret:
            defaultMode: 420
            secretName: grafana-datasources
        - configMap:
            defaultMode: 420
            name: grafana-dashboards
          name: grafana-dashboards
        - configMap:
            defaultMode: 420
            name: grafana-dashboard-k8s-cluster-rsrc-use
          name: grafana-dashboard-k8s-cluster-rsrc-use
        - configMap:
            defaultMode: 420
            name: grafana-dashboard-k8s-node-rsrc-use
          name: grafana-dashboard-k8s-node-rsrc-use
        - configMap:
            defaultMode: 420
            name: grafana-dashboard-k8s-resources-cluster
          name: grafana-dashboard-k8s-resources-cluster
        - configMap:
            defaultMode: 420
            name: grafana-dashboard-k8s-resources-namespace
          name: grafana-dashboard-k8s-resources-namespace
        - configMap:
            defaultMode: 420
            name: grafana-dashboard-k8s-resources-pod
          name: grafana-dashboard-k8s-resources-pod
        - name: grafana-config
          secret:
            defaultMode: 420
            secretName: grafana-config
        - name: secret-grafana-tls
          secret:
            defaultMode: 420
            secretName: grafana-tls
        - name: secret-grafana-proxy
          secret:
            defaultMode: 420
            secretName: grafana-proxy
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: 2018-11-02T10:41:30Z
      lastUpdateTime: 2018-11-02T10:41:48Z
      message: ReplicaSet "grafana-6b9f85786f" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: 2018-11-03T15:55:43Z
      lastUpdateTime: 2018-11-03T15:55:43Z
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1706
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: null
    generation: 1705
    labels:
      app: kube-state-metrics
    name: kube-state-metrics
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: kube-state-metrics
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: kube-state-metrics
      spec:
        containers:
        - args:
          - --secure-listen-address=:8443
          - --upstream=http://127.0.0.1:8081/
          - --tls-cert-file=/etc/tls/private/tls.crt
          - --tls-private-key-file=/etc/tls/private/tls.key
          image: quay.io/coreos/kube-rbac-proxy:v0.3.1
          imagePullPolicy: IfNotPresent
          name: kube-rbac-proxy-main
          ports:
          - containerPort: 8443
            name: https-main
            protocol: TCP
          resources:
            limits:
              cpu: 20m
              memory: 40Mi
            requests:
              cpu: 10m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/tls/private
            name: kube-state-metrics-tls
        - args:
          - --secure-listen-address=:9443
          - --upstream=http://127.0.0.1:8082/
          - --tls-cert-file=/etc/tls/private/tls.crt
          - --tls-private-key-file=/etc/tls/private/tls.key
          image: quay.io/coreos/kube-rbac-proxy:v0.3.1
          imagePullPolicy: IfNotPresent
          name: kube-rbac-proxy-self
          ports:
          - containerPort: 9443
            name: https-self
            protocol: TCP
          resources:
            limits:
              cpu: 20m
              memory: 40Mi
            requests:
              cpu: 10m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/tls/private
            name: kube-state-metrics-tls
        - args:
          - --host=127.0.0.1
          - --port=8081
          - --telemetry-host=127.0.0.1
          - --telemetry-port=8082
          image: quay.io/coreos/kube-state-metrics:v1.3.1
          imagePullPolicy: IfNotPresent
          name: kube-state-metrics
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp
            name: volume-directive-shadow
        dnsPolicy: ClusterFirst
        nodeSelector:
          node-role.kubernetes.io/infra: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kube-state-metrics
        serviceAccountName: kube-state-metrics
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: volume-directive-shadow
        - name: kube-state-metrics-tls
          secret:
            defaultMode: 420
            secretName: kube-state-metrics-tls
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: 2018-11-02T10:45:13Z
      lastUpdateTime: 2018-11-02T10:45:19Z
      message: ReplicaSet "kube-state-metrics-7449d589bc" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: 2018-11-03T15:54:33Z
      lastUpdateTime: 2018-11-03T15:54:33Z
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1705
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: null
    generation: 1708
    labels:
      k8s-app: prometheus-operator
    name: prometheus-operator
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: prometheus-operator
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: prometheus-operator
      spec:
        containers:
        - args:
          - --kubelet-service=kube-system/kubelet
          - --logtostderr=true
          - --config-reloader-image=quay.io/coreos/configmap-reload:v0.0.1
          - --prometheus-config-reloader=quay.io/coreos/prometheus-config-reloader:v0.23.2
          - --namespace=openshift-monitoring
          image: quay.io/coreos/prometheus-operator:v0.23.2
          imagePullPolicy: IfNotPresent
          name: prometheus-operator
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          resources: {}
          securityContext: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          node-role.kubernetes.io/infra: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: prometheus-operator
        serviceAccountName: prometheus-operator
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: 2018-11-02T10:41:04Z
      lastUpdateTime: 2018-11-02T10:41:09Z
      message: ReplicaSet "prometheus-operator-6644b8cd54" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: 2018-11-03T15:54:31Z
      lastUpdateTime: 2018-11-03T15:54:31Z
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1708
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: null
    generation: 1
    labels:
      app: cluster-monitoring-operator
      pod-template-hash: "2021949673"
    name: cluster-monitoring-operator-6465f8fbc7
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: cluster-monitoring-operator
      uid: bff24dd5-de8b-11e8-98d9-fa163eb4fd90
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: cluster-monitoring-operator
        pod-template-hash: "2021949673"
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: cluster-monitoring-operator
          pod-template-hash: "2021949673"
      spec:
        containers:
        - args:
          - -namespace=openshift-monitoring
          - -configmap=cluster-monitoring-config
          - -logtostderr=true
          - -v=4
          image: quay.io/coreos/cluster-monitoring-operator:v0.1.1
          imagePullPolicy: IfNotPresent
          name: cluster-monitoring-operator
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          resources:
            limits:
              cpu: 20m
              memory: 50Mi
            requests:
              cpu: 20m
              memory: 50Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          node-role.kubernetes.io/infra: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: cluster-monitoring-operator
        serviceAccountName: cluster-monitoring-operator
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: null
    generation: 1
    labels:
      app: grafana
      pod-template-hash: "2659413429"
    name: grafana-6b9f85786f
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: grafana
      uid: dba845ce-de8b-11e8-8181-fa163eed49fb
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: grafana
        pod-template-hash: "2659413429"
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: grafana
          pod-template-hash: "2659413429"
      spec:
        containers:
        - args:
          - -config=/etc/grafana/grafana.ini
          image: grafana/grafana:5.2.1
          imagePullPolicy: IfNotPresent
          name: grafana
          ports:
          - containerPort: 3000
            name: http
            protocol: TCP
          resources:
            limits:
              cpu: 200m
              memory: 200Mi
            requests:
              cpu: 100m
              memory: 100Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/grafana
            name: grafana-storage
          - mountPath: /etc/grafana/provisioning/datasources
            name: grafana-datasources
          - mountPath: /etc/grafana/provisioning/dashboards
            name: grafana-dashboards
          - mountPath: /grafana-dashboard-definitions/0/k8s-cluster-rsrc-use
            name: grafana-dashboard-k8s-cluster-rsrc-use
          - mountPath: /grafana-dashboard-definitions/0/k8s-node-rsrc-use
            name: grafana-dashboard-k8s-node-rsrc-use
          - mountPath: /grafana-dashboard-definitions/0/k8s-resources-cluster
            name: grafana-dashboard-k8s-resources-cluster
          - mountPath: /grafana-dashboard-definitions/0/k8s-resources-namespace
            name: grafana-dashboard-k8s-resources-namespace
          - mountPath: /grafana-dashboard-definitions/0/k8s-resources-pod
            name: grafana-dashboard-k8s-resources-pod
          - mountPath: /etc/grafana
            name: grafana-config
        - args:
          - -provider=openshift
          - -https-address=:3000
          - -http-address=
          - -email-domain=*
          - -upstream=http://localhost:3001
          - '-openshift-sar={"resource": "namespaces", "verb": "get"}'
          - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get"}}'
          - -tls-cert=/etc/tls/private/tls.crt
          - -tls-key=/etc/tls/private/tls.key
          - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
          - -cookie-secret-file=/etc/proxy/secrets/session_secret
          - -openshift-service-account=grafana
          - -openshift-ca=/etc/pki/tls/cert.pem
          - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          - -skip-auth-regex=^/metrics
          image: openshift/oauth-proxy:v1.1.0
          imagePullPolicy: IfNotPresent
          name: grafana-proxy
          ports:
          - containerPort: 3000
            name: https
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/tls/private
            name: secret-grafana-tls
          - mountPath: /etc/proxy/secrets
            name: secret-grafana-proxy
        dnsPolicy: ClusterFirst
        nodeSelector:
          node-role.kubernetes.io/infra: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: grafana
        serviceAccountName: grafana
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: grafana-storage
        - name: grafana-datasources
          secret:
            defaultMode: 420
            secretName: grafana-datasources
        - configMap:
            defaultMode: 420
            name: grafana-dashboards
          name: grafana-dashboards
        - configMap:
            defaultMode: 420
            name: grafana-dashboard-k8s-cluster-rsrc-use
          name: grafana-dashboard-k8s-cluster-rsrc-use
        - configMap:
            defaultMode: 420
            name: grafana-dashboard-k8s-node-rsrc-use
          name: grafana-dashboard-k8s-node-rsrc-use
        - configMap:
            defaultMode: 420
            name: grafana-dashboard-k8s-resources-cluster
          name: grafana-dashboard-k8s-resources-cluster
        - configMap:
            defaultMode: 420
            name: grafana-dashboard-k8s-resources-namespace
          name: grafana-dashboard-k8s-resources-namespace
        - configMap:
            defaultMode: 420
            name: grafana-dashboard-k8s-resources-pod
          name: grafana-dashboard-k8s-resources-pod
        - name: grafana-config
          secret:
            defaultMode: 420
            secretName: grafana-config
        - name: secret-grafana-tls
          secret:
            defaultMode: 420
            secretName: grafana-tls
        - name: secret-grafana-proxy
          secret:
            defaultMode: 420
            secretName: grafana-proxy
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: null
    generation: 1
    labels:
      app: kube-state-metrics
      pod-template-hash: "3005814567"
    name: kube-state-metrics-7449d589bc
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: kube-state-metrics
      uid: 60958f89-de8c-11e8-8181-fa163eed49fb
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: kube-state-metrics
        pod-template-hash: "3005814567"
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: kube-state-metrics
          pod-template-hash: "3005814567"
      spec:
        containers:
        - args:
          - --secure-listen-address=:8443
          - --upstream=http://127.0.0.1:8081/
          - --tls-cert-file=/etc/tls/private/tls.crt
          - --tls-private-key-file=/etc/tls/private/tls.key
          image: quay.io/coreos/kube-rbac-proxy:v0.3.1
          imagePullPolicy: IfNotPresent
          name: kube-rbac-proxy-main
          ports:
          - containerPort: 8443
            name: https-main
            protocol: TCP
          resources:
            limits:
              cpu: 20m
              memory: 40Mi
            requests:
              cpu: 10m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/tls/private
            name: kube-state-metrics-tls
        - args:
          - --secure-listen-address=:9443
          - --upstream=http://127.0.0.1:8082/
          - --tls-cert-file=/etc/tls/private/tls.crt
          - --tls-private-key-file=/etc/tls/private/tls.key
          image: quay.io/coreos/kube-rbac-proxy:v0.3.1
          imagePullPolicy: IfNotPresent
          name: kube-rbac-proxy-self
          ports:
          - containerPort: 9443
            name: https-self
            protocol: TCP
          resources:
            limits:
              cpu: 20m
              memory: 40Mi
            requests:
              cpu: 10m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/tls/private
            name: kube-state-metrics-tls
        - args:
          - --host=127.0.0.1
          - --port=8081
          - --telemetry-host=127.0.0.1
          - --telemetry-port=8082
          image: quay.io/coreos/kube-state-metrics:v1.3.1
          imagePullPolicy: IfNotPresent
          name: kube-state-metrics
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp
            name: volume-directive-shadow
        dnsPolicy: ClusterFirst
        nodeSelector:
          node-role.kubernetes.io/infra: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kube-state-metrics
        serviceAccountName: kube-state-metrics
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: volume-directive-shadow
        - name: kube-state-metrics-tls
          secret:
            defaultMode: 420
            secretName: kube-state-metrics-tls
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: null
    generation: 1
    labels:
      k8s-app: prometheus-operator
      pod-template-hash: "2200647810"
    name: prometheus-operator-6644b8cd54
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: prometheus-operator
      uid: cc121281-de8b-11e8-8181-fa163eed49fb
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: prometheus-operator
        pod-template-hash: "2200647810"
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: prometheus-operator
          pod-template-hash: "2200647810"
      spec:
        containers:
        - args:
          - --kubelet-service=kube-system/kubelet
          - --logtostderr=true
          - --config-reloader-image=quay.io/coreos/configmap-reload:v0.0.1
          - --prometheus-config-reloader=quay.io/coreos/prometheus-config-reloader:v0.23.2
          - --namespace=openshift-monitoring
          image: quay.io/coreos/prometheus-operator:v0.23.2
          imagePullPolicy: IfNotPresent
          name: prometheus-operator
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          resources: {}
          securityContext: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          node-role.kubernetes.io/infra: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: prometheus-operator
        serviceAccountName: prometheus-operator
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    creationTimestamp: null
    generation: 1
    labels:
      alertmanager: main
    name: alertmanager-main
    ownerReferences:
    - apiVersion: monitoring.coreos.com/v1
      blockOwnerDeletion: true
      controller: true
      kind: Alertmanager
      name: main
      uid: 214d645b-de8c-11e8-8181-fa163eed49fb
  spec:
    podManagementPolicy: OrderedReady
    replicas: 3
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        alertmanager: main
        app: alertmanager
    serviceName: alertmanager-operated
    template:
      metadata:
        creationTimestamp: null
        labels:
          alertmanager: main
          app: alertmanager
      spec:
        containers:
        - args:
          - --config.file=/etc/alertmanager/config/alertmanager.yaml
          - --cluster.listen-address=$(POD_IP):6783
          - --storage.path=/alertmanager
          - --data.retention=120h
          - --web.listen-address=127.0.0.1:9093
          - --web.external-url=https://alertmanager-main-openshift-monitoring.apps.5.9.163.226.xip.io/
          - --web.route-prefix=/
          - --cluster.peer=alertmanager-main-0.alertmanager-operated.openshift-monitoring.svc:6783
          - --cluster.peer=alertmanager-main-1.alertmanager-operated.openshift-monitoring.svc:6783
          - --cluster.peer=alertmanager-main-2.alertmanager-operated.openshift-monitoring.svc:6783
          env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          image: openshift/prometheus-alertmanager:v0.15.2
          imagePullPolicy: IfNotPresent
          name: alertmanager
          ports:
          - containerPort: 6783
            name: mesh
            protocol: TCP
          resources:
            requests:
              memory: 200Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/alertmanager/config
            name: config-volume
          - mountPath: /alertmanager
            name: alertmanager-main-db
            subPath: alertmanager-db
          - mountPath: /etc/alertmanager/secrets/alertmanager-main-tls
            name: secret-alertmanager-main-tls
            readOnly: true
          - mountPath: /etc/alertmanager/secrets/alertmanager-main-proxy
            name: secret-alertmanager-main-proxy
            readOnly: true
        - args:
          - -webhook-url=http://localhost:9093/-/reload
          - -volume-dir=/etc/alertmanager/config
          image: quay.io/coreos/configmap-reload:v0.0.1
          imagePullPolicy: IfNotPresent
          name: config-reloader
          resources:
            limits:
              cpu: 5m
              memory: 10Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/alertmanager/config
            name: config-volume
            readOnly: true
        - args:
          - -provider=openshift
          - -https-address=:9094
          - -http-address=
          - -email-domain=*
          - -upstream=http://localhost:9093
          - '-openshift-sar={"resource": "namespaces", "verb": "get"}'
          - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get"}}'
          - -tls-cert=/etc/tls/private/tls.crt
          - -tls-key=/etc/tls/private/tls.key
          - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
          - -cookie-secret-file=/etc/proxy/secrets/session_secret
          - -openshift-service-account=alertmanager-main
          - -openshift-ca=/etc/pki/tls/cert.pem
          - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          - -skip-auth-regex=^/metrics
          env:
          - name: HTTP_PROXY
          - name: HTTPS_PROXY
          - name: NO_PROXY
          image: openshift/oauth-proxy:v1.1.0
          imagePullPolicy: IfNotPresent
          name: alertmanager-proxy
          ports:
          - containerPort: 9094
            name: web
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/tls/private
            name: secret-alertmanager-main-tls
          - mountPath: /etc/proxy/secrets
            name: secret-alertmanager-main-proxy
        dnsPolicy: ClusterFirst
        nodeSelector:
          node-role.kubernetes.io/infra: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: alertmanager-main
        serviceAccountName: alertmanager-main
        terminationGracePeriodSeconds: 0
        volumes:
        - name: config-volume
          secret:
            defaultMode: 420
            secretName: alertmanager-main
        - name: secret-alertmanager-main-tls
          secret:
            defaultMode: 420
            secretName: alertmanager-main-tls
        - name: secret-alertmanager-main-proxy
          secret:
            defaultMode: 420
            secretName: alertmanager-main-proxy
    updateStrategy:
      type: RollingUpdate
    volumeClaimTemplates:
    - metadata:
        creationTimestamp: null
        name: alertmanager-main-db
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 2Gi
      status:
        phase: Pending
  status:
    collisionCount: 0
    currentReplicas: 3
    currentRevision: alertmanager-main-d68764d5c
    observedGeneration: 1
    readyReplicas: 3
    replicas: 3
    updateRevision: alertmanager-main-d68764d5c
    updatedReplicas: 3
- apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    annotations:
      prometheus-operator-input-hash: "11277581113931869609"
    creationTimestamp: null
    generation: 1
    labels:
      prometheus: k8s
    name: prometheus-k8s
    ownerReferences:
    - apiVersion: monitoring.coreos.com/v1
      blockOwnerDeletion: true
      controller: true
      kind: Prometheus
      name: k8s
      uid: e9a1eb3a-de8b-11e8-8181-fa163eed49fb
  spec:
    podManagementPolicy: OrderedReady
    replicas: 2
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: prometheus
        prometheus: k8s
    serviceName: prometheus-operated
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: prometheus
          prometheus: k8s
      spec:
        containers:
        - args:
          - --web.console.templates=/etc/prometheus/consoles
          - --web.console.libraries=/etc/prometheus/console_libraries
          - --config.file=/etc/prometheus/config_out/prometheus.env.yaml
          - --storage.tsdb.path=/prometheus
          - --storage.tsdb.retention=15d
          - --web.enable-lifecycle
          - --storage.tsdb.no-lockfile
          - --web.external-url=https://prometheus-k8s-openshift-monitoring.apps.5.9.163.226.xip.io/
          - --web.route-prefix=/
          - --web.listen-address=127.0.0.1:9090
          image: openshift/prometheus:v2.3.2
          imagePullPolicy: IfNotPresent
          name: prometheus
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/prometheus/config_out
            name: config-out
            readOnly: true
          - mountPath: /prometheus
            name: prometheus-k8s-db
            subPath: prometheus-db
          - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
            name: prometheus-k8s-rulefiles-0
          - mountPath: /etc/prometheus/secrets/prometheus-k8s-tls
            name: secret-prometheus-k8s-tls
            readOnly: true
          - mountPath: /etc/prometheus/secrets/prometheus-k8s-proxy
            name: secret-prometheus-k8s-proxy
            readOnly: true
          - mountPath: /etc/prometheus/secrets/prometheus-k8s-htpasswd
            name: secret-prometheus-k8s-htpasswd
            readOnly: true
        - args:
          - --log-format=logfmt
          - --reload-url=http://localhost:9090/-/reload
          - --config-file=/etc/prometheus/config/prometheus.yaml
          - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
          command:
          - /bin/prometheus-config-reloader
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          image: quay.io/coreos/prometheus-config-reloader:v0.23.2
          imagePullPolicy: IfNotPresent
          name: prometheus-config-reloader
          resources:
            limits:
              cpu: 10m
              memory: 50Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/prometheus/config
            name: config
          - mountPath: /etc/prometheus/config_out
            name: config-out
        - args:
          - -provider=openshift
          - -https-address=:9091
          - -http-address=
          - -email-domain=*
          - -upstream=http://localhost:9090
          - -htpasswd-file=/etc/proxy/htpasswd/auth
          - -openshift-service-account=prometheus-k8s
          - '-openshift-sar={"resource": "namespaces", "verb": "get"}'
          - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get"}}'
          - -tls-cert=/etc/tls/private/tls.crt
          - -tls-key=/etc/tls/private/tls.key
          - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
          - -cookie-secret-file=/etc/proxy/secrets/session_secret
          - -openshift-ca=/etc/pki/tls/cert.pem
          - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          - -skip-auth-regex=^/metrics
          image: openshift/oauth-proxy:v1.1.0
          imagePullPolicy: IfNotPresent
          name: prometheus-proxy
          ports:
          - containerPort: 9091
            name: web
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/tls/private
            name: secret-prometheus-k8s-tls
          - mountPath: /etc/proxy/secrets
            name: secret-prometheus-k8s-proxy
          - mountPath: /etc/proxy/htpasswd
            name: secret-prometheus-k8s-htpasswd
        - args:
          - --webhook-url=http://localhost:9090/-/reload
          - --volume-dir=/etc/prometheus/rules/prometheus-k8s-rulefiles-0
          image: quay.io/coreos/configmap-reload:v0.0.1
          imagePullPolicy: IfNotPresent
          name: rules-configmap-reloader
          resources:
            limits:
              cpu: 5m
              memory: 10Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
            name: prometheus-k8s-rulefiles-0
        dnsPolicy: ClusterFirst
        nodeSelector:
          node-role.kubernetes.io/infra: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: prometheus-k8s
        serviceAccountName: prometheus-k8s
        terminationGracePeriodSeconds: 600
        volumes:
        - name: config
          secret:
            defaultMode: 420
            secretName: prometheus-k8s
        - emptyDir: {}
          name: config-out
        - configMap:
            defaultMode: 420
            name: prometheus-k8s-rulefiles-0
          name: prometheus-k8s-rulefiles-0
        - name: secret-prometheus-k8s-tls
          secret:
            defaultMode: 420
            secretName: prometheus-k8s-tls
        - name: secret-prometheus-k8s-proxy
          secret:
            defaultMode: 420
            secretName: prometheus-k8s-proxy
        - name: secret-prometheus-k8s-htpasswd
          secret:
            defaultMode: 420
            secretName: prometheus-k8s-htpasswd
    updateStrategy:
      type: RollingUpdate
    volumeClaimTemplates:
    - metadata:
        creationTimestamp: null
        name: prometheus-k8s-db
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 50Gi
      status:
        phase: Pending
  status:
    collisionCount: 0
    currentReplicas: 2
    currentRevision: prometheus-k8s-548c5f577d
    observedGeneration: 1
    readyReplicas: 2
    replicas: 2
    updateRevision: prometheus-k8s-548c5f577d
    updatedReplicas: 2
- apiVersion: v1
  kind: Route
  metadata:
    annotations:
      openshift.io/host.generated: "true"
    creationTimestamp: null
    name: alertmanager-main
  spec:
    host: alertmanager-main-openshift-monitoring.apps.5.9.163.226.xip.io
    port:
      targetPort: web
    tls:
      termination: reencrypt
    to:
      kind: Service
      name: alertmanager-main
      weight: 100
    wildcardPolicy: None
  status:
    ingress:
    - conditions:
      - lastTransitionTime: 2018-11-02T10:43:24Z
        status: "True"
        type: Admitted
      host: alertmanager-main-openshift-monitoring.apps.5.9.163.226.xip.io
      routerName: router
      wildcardPolicy: None
- apiVersion: v1
  kind: Route
  metadata:
    annotations:
      openshift.io/host.generated: "true"
    creationTimestamp: null
    name: grafana
  spec:
    host: grafana-openshift-monitoring.apps.5.9.163.226.xip.io
    port:
      targetPort: https
    tls:
      termination: reencrypt
    to:
      kind: Service
      name: grafana
      weight: 100
    wildcardPolicy: None
  status:
    ingress:
    - conditions:
      - lastTransitionTime: 2018-11-02T10:41:27Z
        status: "True"
        type: Admitted
      host: grafana-openshift-monitoring.apps.5.9.163.226.xip.io
      routerName: router
      wildcardPolicy: None
- apiVersion: v1
  kind: Route
  metadata:
    annotations:
      openshift.io/host.generated: "true"
    creationTimestamp: null
    name: prometheus-k8s
  spec:
    host: prometheus-k8s-openshift-monitoring.apps.5.9.163.226.xip.io
    port:
      targetPort: web
    tls:
      termination: reencrypt
    to:
      kind: Service
      name: prometheus-k8s
      weight: 100
    wildcardPolicy: None
  status:
    ingress:
    - conditions:
      - lastTransitionTime: 2018-11-02T10:41:49Z
        status: "True"
        type: Admitted
      host: prometheus-k8s-openshift-monitoring.apps.5.9.163.226.xip.io
      routerName: router
      wildcardPolicy: None
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: restricted
    creationTimestamp: null
    generateName: alertmanager-main-
    labels:
      alertmanager: main
      app: alertmanager
      controller-revision-hash: alertmanager-main-d68764d5c
      statefulset.kubernetes.io/pod-name: alertmanager-main-0
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: alertmanager-main
      uid: 215902d3-de8c-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - --config.file=/etc/alertmanager/config/alertmanager.yaml
      - --cluster.listen-address=$(POD_IP):6783
      - --storage.path=/alertmanager
      - --data.retention=120h
      - --web.listen-address=127.0.0.1:9093
      - --web.external-url=https://alertmanager-main-openshift-monitoring.apps.5.9.163.226.xip.io/
      - --web.route-prefix=/
      - --cluster.peer=alertmanager-main-0.alertmanager-operated.openshift-monitoring.svc:6783
      - --cluster.peer=alertmanager-main-1.alertmanager-operated.openshift-monitoring.svc:6783
      - --cluster.peer=alertmanager-main-2.alertmanager-operated.openshift-monitoring.svc:6783
      env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: openshift/prometheus-alertmanager:v0.15.2
      imagePullPolicy: IfNotPresent
      name: alertmanager
      ports:
      - containerPort: 6783
        name: mesh
        protocol: TCP
      resources:
        requests:
          memory: 200Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
      - mountPath: /alertmanager
        name: alertmanager-main-db
        subPath: alertmanager-db
      - mountPath: /etc/alertmanager/secrets/alertmanager-main-tls
        name: secret-alertmanager-main-tls
        readOnly: true
      - mountPath: /etc/alertmanager/secrets/alertmanager-main-proxy
        name: secret-alertmanager-main-proxy
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: alertmanager-main-token-889z8
        readOnly: true
    - args:
      - -webhook-url=http://localhost:9093/-/reload
      - -volume-dir=/etc/alertmanager/config
      image: quay.io/coreos/configmap-reload:v0.0.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      resources:
        limits:
          cpu: 5m
          memory: 10Mi
        requests:
          cpu: 5m
          memory: 10Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: alertmanager-main-token-889z8
        readOnly: true
    - args:
      - -provider=openshift
      - -https-address=:9094
      - -http-address=
      - -email-domain=*
      - -upstream=http://localhost:9093
      - '-openshift-sar={"resource": "namespaces", "verb": "get"}'
      - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get"}}'
      - -tls-cert=/etc/tls/private/tls.crt
      - -tls-key=/etc/tls/private/tls.key
      - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
      - -cookie-secret-file=/etc/proxy/secrets/session_secret
      - -openshift-service-account=alertmanager-main
      - -openshift-ca=/etc/pki/tls/cert.pem
      - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      - -skip-auth-regex=^/metrics
      env:
      - name: HTTP_PROXY
      - name: HTTPS_PROXY
      - name: NO_PROXY
      image: openshift/oauth-proxy:v1.1.0
      imagePullPolicy: IfNotPresent
      name: alertmanager-proxy
      ports:
      - containerPort: 9094
        name: web
        protocol: TCP
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-alertmanager-main-tls
      - mountPath: /etc/proxy/secrets
        name: secret-alertmanager-main-proxy
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: alertmanager-main-token-889z8
        readOnly: true
    dnsPolicy: ClusterFirst
    hostname: alertmanager-main-0
    imagePullSecrets:
    - name: alertmanager-main-dockercfg-mqnn2
    nodeName: infra1
    nodeSelector:
      node-role.kubernetes.io/infra: "true"
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000150000
      seLinuxOptions:
        level: s0:c12,c9
    serviceAccount: alertmanager-main
    serviceAccountName: alertmanager-main
    subdomain: alertmanager-operated
    terminationGracePeriodSeconds: 0
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - name: alertmanager-main-db
      persistentVolumeClaim:
        claimName: alertmanager-main-db-alertmanager-main-0
    - name: config-volume
      secret:
        defaultMode: 420
        secretName: alertmanager-main
    - name: secret-alertmanager-main-tls
      secret:
        defaultMode: 420
        secretName: alertmanager-main-tls
    - name: secret-alertmanager-main-proxy
      secret:
        defaultMode: 420
        secretName: alertmanager-main-proxy
    - name: alertmanager-main-token-889z8
      secret:
        defaultMode: 420
        secretName: alertmanager-main-token-889z8
  status:
    phase: Pending
    qosClass: Burstable
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: restricted
    creationTimestamp: null
    generateName: alertmanager-main-
    labels:
      alertmanager: main
      app: alertmanager
      controller-revision-hash: alertmanager-main-d68764d5c
      statefulset.kubernetes.io/pod-name: alertmanager-main-1
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: alertmanager-main
      uid: 215902d3-de8c-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - --config.file=/etc/alertmanager/config/alertmanager.yaml
      - --cluster.listen-address=$(POD_IP):6783
      - --storage.path=/alertmanager
      - --data.retention=120h
      - --web.listen-address=127.0.0.1:9093
      - --web.external-url=https://alertmanager-main-openshift-monitoring.apps.5.9.163.226.xip.io/
      - --web.route-prefix=/
      - --cluster.peer=alertmanager-main-0.alertmanager-operated.openshift-monitoring.svc:6783
      - --cluster.peer=alertmanager-main-1.alertmanager-operated.openshift-monitoring.svc:6783
      - --cluster.peer=alertmanager-main-2.alertmanager-operated.openshift-monitoring.svc:6783
      env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: openshift/prometheus-alertmanager:v0.15.2
      imagePullPolicy: IfNotPresent
      name: alertmanager
      ports:
      - containerPort: 6783
        name: mesh
        protocol: TCP
      resources:
        requests:
          memory: 200Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
      - mountPath: /alertmanager
        name: alertmanager-main-db
        subPath: alertmanager-db
      - mountPath: /etc/alertmanager/secrets/alertmanager-main-tls
        name: secret-alertmanager-main-tls
        readOnly: true
      - mountPath: /etc/alertmanager/secrets/alertmanager-main-proxy
        name: secret-alertmanager-main-proxy
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: alertmanager-main-token-889z8
        readOnly: true
    - args:
      - -webhook-url=http://localhost:9093/-/reload
      - -volume-dir=/etc/alertmanager/config
      image: quay.io/coreos/configmap-reload:v0.0.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      resources:
        limits:
          cpu: 5m
          memory: 10Mi
        requests:
          cpu: 5m
          memory: 10Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: alertmanager-main-token-889z8
        readOnly: true
    - args:
      - -provider=openshift
      - -https-address=:9094
      - -http-address=
      - -email-domain=*
      - -upstream=http://localhost:9093
      - '-openshift-sar={"resource": "namespaces", "verb": "get"}'
      - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get"}}'
      - -tls-cert=/etc/tls/private/tls.crt
      - -tls-key=/etc/tls/private/tls.key
      - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
      - -cookie-secret-file=/etc/proxy/secrets/session_secret
      - -openshift-service-account=alertmanager-main
      - -openshift-ca=/etc/pki/tls/cert.pem
      - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      - -skip-auth-regex=^/metrics
      env:
      - name: HTTP_PROXY
      - name: HTTPS_PROXY
      - name: NO_PROXY
      image: openshift/oauth-proxy:v1.1.0
      imagePullPolicy: IfNotPresent
      name: alertmanager-proxy
      ports:
      - containerPort: 9094
        name: web
        protocol: TCP
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-alertmanager-main-tls
      - mountPath: /etc/proxy/secrets
        name: secret-alertmanager-main-proxy
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: alertmanager-main-token-889z8
        readOnly: true
    dnsPolicy: ClusterFirst
    hostname: alertmanager-main-1
    imagePullSecrets:
    - name: alertmanager-main-dockercfg-mqnn2
    nodeName: infra0
    nodeSelector:
      node-role.kubernetes.io/infra: "true"
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000150000
      seLinuxOptions:
        level: s0:c12,c9
    serviceAccount: alertmanager-main
    serviceAccountName: alertmanager-main
    subdomain: alertmanager-operated
    terminationGracePeriodSeconds: 0
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - name: alertmanager-main-db
      persistentVolumeClaim:
        claimName: alertmanager-main-db-alertmanager-main-1
    - name: config-volume
      secret:
        defaultMode: 420
        secretName: alertmanager-main
    - name: secret-alertmanager-main-tls
      secret:
        defaultMode: 420
        secretName: alertmanager-main-tls
    - name: secret-alertmanager-main-proxy
      secret:
        defaultMode: 420
        secretName: alertmanager-main-proxy
    - name: alertmanager-main-token-889z8
      secret:
        defaultMode: 420
        secretName: alertmanager-main-token-889z8
  status:
    phase: Pending
    qosClass: Burstable
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: restricted
    creationTimestamp: null
    generateName: alertmanager-main-
    labels:
      alertmanager: main
      app: alertmanager
      controller-revision-hash: alertmanager-main-d68764d5c
      statefulset.kubernetes.io/pod-name: alertmanager-main-2
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: alertmanager-main
      uid: 215902d3-de8c-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - --config.file=/etc/alertmanager/config/alertmanager.yaml
      - --cluster.listen-address=$(POD_IP):6783
      - --storage.path=/alertmanager
      - --data.retention=120h
      - --web.listen-address=127.0.0.1:9093
      - --web.external-url=https://alertmanager-main-openshift-monitoring.apps.5.9.163.226.xip.io/
      - --web.route-prefix=/
      - --cluster.peer=alertmanager-main-0.alertmanager-operated.openshift-monitoring.svc:6783
      - --cluster.peer=alertmanager-main-1.alertmanager-operated.openshift-monitoring.svc:6783
      - --cluster.peer=alertmanager-main-2.alertmanager-operated.openshift-monitoring.svc:6783
      env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: openshift/prometheus-alertmanager:v0.15.2
      imagePullPolicy: IfNotPresent
      name: alertmanager
      ports:
      - containerPort: 6783
        name: mesh
        protocol: TCP
      resources:
        requests:
          memory: 200Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
      - mountPath: /alertmanager
        name: alertmanager-main-db
        subPath: alertmanager-db
      - mountPath: /etc/alertmanager/secrets/alertmanager-main-tls
        name: secret-alertmanager-main-tls
        readOnly: true
      - mountPath: /etc/alertmanager/secrets/alertmanager-main-proxy
        name: secret-alertmanager-main-proxy
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: alertmanager-main-token-889z8
        readOnly: true
    - args:
      - -webhook-url=http://localhost:9093/-/reload
      - -volume-dir=/etc/alertmanager/config
      image: quay.io/coreos/configmap-reload:v0.0.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      resources:
        limits:
          cpu: 5m
          memory: 10Mi
        requests:
          cpu: 5m
          memory: 10Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: alertmanager-main-token-889z8
        readOnly: true
    - args:
      - -provider=openshift
      - -https-address=:9094
      - -http-address=
      - -email-domain=*
      - -upstream=http://localhost:9093
      - '-openshift-sar={"resource": "namespaces", "verb": "get"}'
      - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get"}}'
      - -tls-cert=/etc/tls/private/tls.crt
      - -tls-key=/etc/tls/private/tls.key
      - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
      - -cookie-secret-file=/etc/proxy/secrets/session_secret
      - -openshift-service-account=alertmanager-main
      - -openshift-ca=/etc/pki/tls/cert.pem
      - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      - -skip-auth-regex=^/metrics
      env:
      - name: HTTP_PROXY
      - name: HTTPS_PROXY
      - name: NO_PROXY
      image: openshift/oauth-proxy:v1.1.0
      imagePullPolicy: IfNotPresent
      name: alertmanager-proxy
      ports:
      - containerPort: 9094
        name: web
        protocol: TCP
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-alertmanager-main-tls
      - mountPath: /etc/proxy/secrets
        name: secret-alertmanager-main-proxy
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: alertmanager-main-token-889z8
        readOnly: true
    dnsPolicy: ClusterFirst
    hostname: alertmanager-main-2
    imagePullSecrets:
    - name: alertmanager-main-dockercfg-mqnn2
    nodeName: infra0
    nodeSelector:
      node-role.kubernetes.io/infra: "true"
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000150000
      seLinuxOptions:
        level: s0:c12,c9
    serviceAccount: alertmanager-main
    serviceAccountName: alertmanager-main
    subdomain: alertmanager-operated
    terminationGracePeriodSeconds: 0
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - name: alertmanager-main-db
      persistentVolumeClaim:
        claimName: alertmanager-main-db-alertmanager-main-2
    - name: config-volume
      secret:
        defaultMode: 420
        secretName: alertmanager-main
    - name: secret-alertmanager-main-tls
      secret:
        defaultMode: 420
        secretName: alertmanager-main-tls
    - name: secret-alertmanager-main-proxy
      secret:
        defaultMode: 420
        secretName: alertmanager-main-proxy
    - name: alertmanager-main-token-889z8
      secret:
        defaultMode: 420
        secretName: alertmanager-main-token-889z8
  status:
    phase: Pending
    qosClass: Burstable
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: restricted
    creationTimestamp: null
    generateName: cluster-monitoring-operator-6465f8fbc7-
    labels:
      app: cluster-monitoring-operator
      pod-template-hash: "2021949673"
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: cluster-monitoring-operator-6465f8fbc7
      uid: bfc8c42b-de8b-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - -namespace=openshift-monitoring
      - -configmap=cluster-monitoring-config
      - -logtostderr=true
      - -v=4
      image: quay.io/coreos/cluster-monitoring-operator:v0.1.1
      imagePullPolicy: IfNotPresent
      name: cluster-monitoring-operator
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      resources:
        limits:
          cpu: 20m
          memory: 50Mi
        requests:
          cpu: 20m
          memory: 50Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: cluster-monitoring-operator-token-48hcj
        readOnly: true
    dnsPolicy: ClusterFirst
    imagePullSecrets:
    - name: cluster-monitoring-operator-dockercfg-jf5kp
    nodeName: infra1
    nodeSelector:
      node-role.kubernetes.io/infra: "true"
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000150000
      seLinuxOptions:
        level: s0:c12,c9
    serviceAccount: cluster-monitoring-operator
    serviceAccountName: cluster-monitoring-operator
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - name: cluster-monitoring-operator-token-48hcj
      secret:
        defaultMode: 420
        secretName: cluster-monitoring-operator-token-48hcj
  status:
    phase: Pending
    qosClass: Guaranteed
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: restricted
    creationTimestamp: null
    generateName: grafana-6b9f85786f-
    labels:
      app: grafana
      pod-template-hash: "2659413429"
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: grafana-6b9f85786f
      uid: dbaec95f-de8b-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - -config=/etc/grafana/grafana.ini
      image: grafana/grafana:5.2.1
      imagePullPolicy: IfNotPresent
      name: grafana
      ports:
      - containerPort: 3000
        name: http
        protocol: TCP
      resources:
        limits:
          cpu: 200m
          memory: 200Mi
        requests:
          cpu: 100m
          memory: 100Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/grafana
        name: grafana-storage
      - mountPath: /etc/grafana/provisioning/datasources
        name: grafana-datasources
      - mountPath: /etc/grafana/provisioning/dashboards
        name: grafana-dashboards
      - mountPath: /grafana-dashboard-definitions/0/k8s-cluster-rsrc-use
        name: grafana-dashboard-k8s-cluster-rsrc-use
      - mountPath: /grafana-dashboard-definitions/0/k8s-node-rsrc-use
        name: grafana-dashboard-k8s-node-rsrc-use
      - mountPath: /grafana-dashboard-definitions/0/k8s-resources-cluster
        name: grafana-dashboard-k8s-resources-cluster
      - mountPath: /grafana-dashboard-definitions/0/k8s-resources-namespace
        name: grafana-dashboard-k8s-resources-namespace
      - mountPath: /grafana-dashboard-definitions/0/k8s-resources-pod
        name: grafana-dashboard-k8s-resources-pod
      - mountPath: /etc/grafana
        name: grafana-config
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: grafana-token-ntws5
        readOnly: true
    - args:
      - -provider=openshift
      - -https-address=:3000
      - -http-address=
      - -email-domain=*
      - -upstream=http://localhost:3001
      - '-openshift-sar={"resource": "namespaces", "verb": "get"}'
      - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get"}}'
      - -tls-cert=/etc/tls/private/tls.crt
      - -tls-key=/etc/tls/private/tls.key
      - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
      - -cookie-secret-file=/etc/proxy/secrets/session_secret
      - -openshift-service-account=grafana
      - -openshift-ca=/etc/pki/tls/cert.pem
      - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      - -skip-auth-regex=^/metrics
      image: openshift/oauth-proxy:v1.1.0
      imagePullPolicy: IfNotPresent
      name: grafana-proxy
      ports:
      - containerPort: 3000
        name: https
        protocol: TCP
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-grafana-tls
      - mountPath: /etc/proxy/secrets
        name: secret-grafana-proxy
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: grafana-token-ntws5
        readOnly: true
    dnsPolicy: ClusterFirst
    imagePullSecrets:
    - name: grafana-dockercfg-9b5j6
    nodeName: infra0
    nodeSelector:
      node-role.kubernetes.io/infra: "true"
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000150000
      seLinuxOptions:
        level: s0:c12,c9
    serviceAccount: grafana
    serviceAccountName: grafana
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - emptyDir: {}
      name: grafana-storage
    - name: grafana-datasources
      secret:
        defaultMode: 420
        secretName: grafana-datasources
    - configMap:
        defaultMode: 420
        name: grafana-dashboards
      name: grafana-dashboards
    - configMap:
        defaultMode: 420
        name: grafana-dashboard-k8s-cluster-rsrc-use
      name: grafana-dashboard-k8s-cluster-rsrc-use
    - configMap:
        defaultMode: 420
        name: grafana-dashboard-k8s-node-rsrc-use
      name: grafana-dashboard-k8s-node-rsrc-use
    - configMap:
        defaultMode: 420
        name: grafana-dashboard-k8s-resources-cluster
      name: grafana-dashboard-k8s-resources-cluster
    - configMap:
        defaultMode: 420
        name: grafana-dashboard-k8s-resources-namespace
      name: grafana-dashboard-k8s-resources-namespace
    - configMap:
        defaultMode: 420
        name: grafana-dashboard-k8s-resources-pod
      name: grafana-dashboard-k8s-resources-pod
    - name: grafana-config
      secret:
        defaultMode: 420
        secretName: grafana-config
    - name: secret-grafana-tls
      secret:
        defaultMode: 420
        secretName: grafana-tls
    - name: secret-grafana-proxy
      secret:
        defaultMode: 420
        secretName: grafana-proxy
    - name: grafana-token-ntws5
      secret:
        defaultMode: 420
        secretName: grafana-token-ntws5
  status:
    phase: Pending
    qosClass: Burstable
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: restricted
    creationTimestamp: null
    generateName: kube-state-metrics-7449d589bc-
    labels:
      app: kube-state-metrics
      pod-template-hash: "3005814567"
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kube-state-metrics-7449d589bc
      uid: 609f7f77-de8c-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - --secure-listen-address=:8443
      - --upstream=http://127.0.0.1:8081/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/coreos/kube-rbac-proxy:v0.3.1
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy-main
      ports:
      - containerPort: 8443
        name: https-main
        protocol: TCP
      resources:
        limits:
          cpu: 20m
          memory: 40Mi
        requests:
          cpu: 10m
          memory: 20Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: kube-state-metrics-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-state-metrics-token-cwj2r
        readOnly: true
    - args:
      - --secure-listen-address=:9443
      - --upstream=http://127.0.0.1:8082/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/coreos/kube-rbac-proxy:v0.3.1
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy-self
      ports:
      - containerPort: 9443
        name: https-self
        protocol: TCP
      resources:
        limits:
          cpu: 20m
          memory: 40Mi
        requests:
          cpu: 10m
          memory: 20Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: kube-state-metrics-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-state-metrics-token-cwj2r
        readOnly: true
    - args:
      - --host=127.0.0.1
      - --port=8081
      - --telemetry-host=127.0.0.1
      - --telemetry-port=8082
      image: quay.io/coreos/kube-state-metrics:v1.3.1
      imagePullPolicy: IfNotPresent
      name: kube-state-metrics
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: volume-directive-shadow
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-state-metrics-token-cwj2r
        readOnly: true
    dnsPolicy: ClusterFirst
    imagePullSecrets:
    - name: kube-state-metrics-dockercfg-bxtbj
    nodeName: infra1
    nodeSelector:
      node-role.kubernetes.io/infra: "true"
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000150000
      seLinuxOptions:
        level: s0:c12,c9
    serviceAccount: kube-state-metrics
    serviceAccountName: kube-state-metrics
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - emptyDir: {}
      name: volume-directive-shadow
    - name: kube-state-metrics-tls
      secret:
        defaultMode: 420
        secretName: kube-state-metrics-tls
    - name: kube-state-metrics-token-cwj2r
      secret:
        defaultMode: 420
        secretName: kube-state-metrics-token-cwj2r
  status:
    phase: Pending
    qosClass: Burstable
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: node-exporter
    creationTimestamp: null
    generateName: node-exporter-
    labels:
      app: node-exporter
      controller-revision-hash: "2211714444"
      pod-template-generation: "1"
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: 515dbb66-de8c-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9101
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
      - --no-collector.wifi
      image: openshift/prometheus-node-exporter:v0.16.0
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
      - mountPath: /host/sys
        name: sys
      - mountPath: /host/root
        name: root
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    - args:
      - --secure-listen-address=:9100
      - --upstream=http://127.0.0.1:9101/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/coreos/kube-rbac-proxy:v0.3.1
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: 20m
          memory: 40Mi
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: node-exporter-dockercfg-4jhpb
    nodeName: node0
    nodeSelector:
      beta.kubernetes.io/os: linux
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - name: node-exporter-token-rxz99
      secret:
        defaultMode: 420
        secretName: node-exporter-token-rxz99
  status:
    phase: Pending
    qosClass: Burstable
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: node-exporter
    creationTimestamp: null
    generateName: node-exporter-
    labels:
      app: node-exporter
      controller-revision-hash: "2211714444"
      pod-template-generation: "1"
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: 515dbb66-de8c-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9101
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
      - --no-collector.wifi
      image: openshift/prometheus-node-exporter:v0.16.0
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
      - mountPath: /host/sys
        name: sys
      - mountPath: /host/root
        name: root
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    - args:
      - --secure-listen-address=:9100
      - --upstream=http://127.0.0.1:9101/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/coreos/kube-rbac-proxy:v0.3.1
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: 20m
          memory: 40Mi
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: node-exporter-dockercfg-4jhpb
    nodeName: node4
    nodeSelector:
      beta.kubernetes.io/os: linux
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - name: node-exporter-token-rxz99
      secret:
        defaultMode: 420
        secretName: node-exporter-token-rxz99
  status:
    phase: Pending
    qosClass: Burstable
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: node-exporter
    creationTimestamp: null
    generateName: node-exporter-
    labels:
      app: node-exporter
      controller-revision-hash: "2211714444"
      pod-template-generation: "1"
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: 515dbb66-de8c-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9101
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
      - --no-collector.wifi
      image: openshift/prometheus-node-exporter:v0.16.0
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
      - mountPath: /host/sys
        name: sys
      - mountPath: /host/root
        name: root
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    - args:
      - --secure-listen-address=:9100
      - --upstream=http://127.0.0.1:9101/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/coreos/kube-rbac-proxy:v0.3.1
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: 20m
          memory: 40Mi
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: node-exporter-dockercfg-4jhpb
    nodeName: node2
    nodeSelector:
      beta.kubernetes.io/os: linux
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - name: node-exporter-token-rxz99
      secret:
        defaultMode: 420
        secretName: node-exporter-token-rxz99
  status:
    phase: Pending
    qosClass: Burstable
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: node-exporter
    creationTimestamp: null
    generateName: node-exporter-
    labels:
      app: node-exporter
      controller-revision-hash: "2211714444"
      pod-template-generation: "1"
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: 515dbb66-de8c-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9101
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
      - --no-collector.wifi
      image: openshift/prometheus-node-exporter:v0.16.0
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
      - mountPath: /host/sys
        name: sys
      - mountPath: /host/root
        name: root
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    - args:
      - --secure-listen-address=:9100
      - --upstream=http://127.0.0.1:9101/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/coreos/kube-rbac-proxy:v0.3.1
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: 20m
          memory: 40Mi
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: node-exporter-dockercfg-4jhpb
    nodeName: node3
    nodeSelector:
      beta.kubernetes.io/os: linux
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - name: node-exporter-token-rxz99
      secret:
        defaultMode: 420
        secretName: node-exporter-token-rxz99
  status:
    phase: Pending
    qosClass: Burstable
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: node-exporter
    creationTimestamp: null
    generateName: node-exporter-
    labels:
      app: node-exporter
      controller-revision-hash: "2211714444"
      pod-template-generation: "1"
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: 515dbb66-de8c-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9101
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
      - --no-collector.wifi
      image: openshift/prometheus-node-exporter:v0.16.0
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
      - mountPath: /host/sys
        name: sys
      - mountPath: /host/root
        name: root
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    - args:
      - --secure-listen-address=:9100
      - --upstream=http://127.0.0.1:9101/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/coreos/kube-rbac-proxy:v0.3.1
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: 20m
          memory: 40Mi
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: node-exporter-dockercfg-4jhpb
    nodeName: infra1
    nodeSelector:
      beta.kubernetes.io/os: linux
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - name: node-exporter-token-rxz99
      secret:
        defaultMode: 420
        secretName: node-exporter-token-rxz99
  status:
    phase: Pending
    qosClass: Burstable
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: node-exporter
    creationTimestamp: null
    generateName: node-exporter-
    labels:
      app: node-exporter
      controller-revision-hash: "2211714444"
      pod-template-generation: "1"
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: 515dbb66-de8c-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9101
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
      - --no-collector.wifi
      image: openshift/prometheus-node-exporter:v0.16.0
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
      - mountPath: /host/sys
        name: sys
      - mountPath: /host/root
        name: root
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    - args:
      - --secure-listen-address=:9100
      - --upstream=http://127.0.0.1:9101/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/coreos/kube-rbac-proxy:v0.3.1
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: 20m
          memory: 40Mi
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: node-exporter-dockercfg-4jhpb
    nodeName: master2
    nodeSelector:
      beta.kubernetes.io/os: linux
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - name: node-exporter-token-rxz99
      secret:
        defaultMode: 420
        secretName: node-exporter-token-rxz99
  status:
    phase: Pending
    qosClass: Burstable
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: node-exporter
    creationTimestamp: null
    generateName: node-exporter-
    labels:
      app: node-exporter
      controller-revision-hash: "2211714444"
      pod-template-generation: "1"
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: 515dbb66-de8c-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9101
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
      - --no-collector.wifi
      image: openshift/prometheus-node-exporter:v0.16.0
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
      - mountPath: /host/sys
        name: sys
      - mountPath: /host/root
        name: root
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    - args:
      - --secure-listen-address=:9100
      - --upstream=http://127.0.0.1:9101/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/coreos/kube-rbac-proxy:v0.3.1
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: 20m
          memory: 40Mi
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: node-exporter-dockercfg-4jhpb
    nodeName: master0
    nodeSelector:
      beta.kubernetes.io/os: linux
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - name: node-exporter-token-rxz99
      secret:
        defaultMode: 420
        secretName: node-exporter-token-rxz99
  status:
    phase: Pending
    qosClass: Burstable
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: node-exporter
    creationTimestamp: null
    generateName: node-exporter-
    labels:
      app: node-exporter
      controller-revision-hash: "2211714444"
      pod-template-generation: "1"
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: 515dbb66-de8c-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9101
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
      - --no-collector.wifi
      image: openshift/prometheus-node-exporter:v0.16.0
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
      - mountPath: /host/sys
        name: sys
      - mountPath: /host/root
        name: root
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    - args:
      - --secure-listen-address=:9100
      - --upstream=http://127.0.0.1:9101/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/coreos/kube-rbac-proxy:v0.3.1
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: 20m
          memory: 40Mi
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: node-exporter-dockercfg-4jhpb
    nodeName: infra0
    nodeSelector:
      beta.kubernetes.io/os: linux
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - name: node-exporter-token-rxz99
      secret:
        defaultMode: 420
        secretName: node-exporter-token-rxz99
  status:
    phase: Pending
    qosClass: Burstable
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: node-exporter
    creationTimestamp: null
    generateName: node-exporter-
    labels:
      app: node-exporter
      controller-revision-hash: "2211714444"
      pod-template-generation: "1"
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: 515dbb66-de8c-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9101
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
      - --no-collector.wifi
      image: openshift/prometheus-node-exporter:v0.16.0
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
      - mountPath: /host/sys
        name: sys
      - mountPath: /host/root
        name: root
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    - args:
      - --secure-listen-address=:9100
      - --upstream=http://127.0.0.1:9101/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/coreos/kube-rbac-proxy:v0.3.1
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: 20m
          memory: 40Mi
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: node-exporter-dockercfg-4jhpb
    nodeName: node5
    nodeSelector:
      beta.kubernetes.io/os: linux
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - name: node-exporter-token-rxz99
      secret:
        defaultMode: 420
        secretName: node-exporter-token-rxz99
  status:
    phase: Pending
    qosClass: Burstable
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: node-exporter
    creationTimestamp: null
    generateName: node-exporter-
    labels:
      app: node-exporter
      controller-revision-hash: "2211714444"
      pod-template-generation: "1"
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: 515dbb66-de8c-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9101
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
      - --no-collector.wifi
      image: openshift/prometheus-node-exporter:v0.16.0
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
      - mountPath: /host/sys
        name: sys
      - mountPath: /host/root
        name: root
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    - args:
      - --secure-listen-address=:9100
      - --upstream=http://127.0.0.1:9101/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/coreos/kube-rbac-proxy:v0.3.1
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: 20m
          memory: 40Mi
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: node-exporter-dockercfg-4jhpb
    nodeName: node1
    nodeSelector:
      beta.kubernetes.io/os: linux
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - name: node-exporter-token-rxz99
      secret:
        defaultMode: 420
        secretName: node-exporter-token-rxz99
  status:
    phase: Pending
    qosClass: Burstable
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: node-exporter
    creationTimestamp: null
    generateName: node-exporter-
    labels:
      app: node-exporter
      controller-revision-hash: "2211714444"
      pod-template-generation: "1"
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: 515dbb66-de8c-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9101
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
      - --no-collector.wifi
      image: openshift/prometheus-node-exporter:v0.16.0
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
      - mountPath: /host/sys
        name: sys
      - mountPath: /host/root
        name: root
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    - args:
      - --secure-listen-address=:9100
      - --upstream=http://127.0.0.1:9101/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/coreos/kube-rbac-proxy:v0.3.1
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: 20m
          memory: 40Mi
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: node-exporter-token-rxz99
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: node-exporter-dockercfg-4jhpb
    nodeName: master1
    nodeSelector:
      beta.kubernetes.io/os: linux
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - name: node-exporter-token-rxz99
      secret:
        defaultMode: 420
        secretName: node-exporter-token-rxz99
  status:
    phase: Pending
    qosClass: Burstable
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: restricted
    creationTimestamp: null
    generateName: prometheus-k8s-
    labels:
      app: prometheus
      controller-revision-hash: prometheus-k8s-548c5f577d
      prometheus: k8s
      statefulset.kubernetes.io/pod-name: prometheus-k8s-0
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: prometheus-k8s
      uid: e9c51ffb-de8b-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - --web.console.templates=/etc/prometheus/consoles
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --config.file=/etc/prometheus/config_out/prometheus.env.yaml
      - --storage.tsdb.path=/prometheus
      - --storage.tsdb.retention=15d
      - --web.enable-lifecycle
      - --storage.tsdb.no-lockfile
      - --web.external-url=https://prometheus-k8s-openshift-monitoring.apps.5.9.163.226.xip.io/
      - --web.route-prefix=/
      - --web.listen-address=127.0.0.1:9090
      image: openshift/prometheus:v2.3.2
      imagePullPolicy: IfNotPresent
      name: prometheus
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/prometheus/config_out
        name: config-out
        readOnly: true
      - mountPath: /prometheus
        name: prometheus-k8s-db
        subPath: prometheus-db
      - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
        name: prometheus-k8s-rulefiles-0
      - mountPath: /etc/prometheus/secrets/prometheus-k8s-tls
        name: secret-prometheus-k8s-tls
        readOnly: true
      - mountPath: /etc/prometheus/secrets/prometheus-k8s-proxy
        name: secret-prometheus-k8s-proxy
        readOnly: true
      - mountPath: /etc/prometheus/secrets/prometheus-k8s-htpasswd
        name: secret-prometheus-k8s-htpasswd
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: prometheus-k8s-token-7fw4s
        readOnly: true
    - args:
      - --log-format=logfmt
      - --reload-url=http://localhost:9090/-/reload
      - --config-file=/etc/prometheus/config/prometheus.yaml
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      image: quay.io/coreos/prometheus-config-reloader:v0.23.2
      imagePullPolicy: IfNotPresent
      name: prometheus-config-reloader
      resources:
        limits:
          cpu: 10m
          memory: 50Mi
        requests:
          cpu: 10m
          memory: 50Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: prometheus-k8s-token-7fw4s
        readOnly: true
    - args:
      - -provider=openshift
      - -https-address=:9091
      - -http-address=
      - -email-domain=*
      - -upstream=http://localhost:9090
      - -htpasswd-file=/etc/proxy/htpasswd/auth
      - -openshift-service-account=prometheus-k8s
      - '-openshift-sar={"resource": "namespaces", "verb": "get"}'
      - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get"}}'
      - -tls-cert=/etc/tls/private/tls.crt
      - -tls-key=/etc/tls/private/tls.key
      - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
      - -cookie-secret-file=/etc/proxy/secrets/session_secret
      - -openshift-ca=/etc/pki/tls/cert.pem
      - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      - -skip-auth-regex=^/metrics
      image: openshift/oauth-proxy:v1.1.0
      imagePullPolicy: IfNotPresent
      name: prometheus-proxy
      ports:
      - containerPort: 9091
        name: web
        protocol: TCP
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-prometheus-k8s-tls
      - mountPath: /etc/proxy/secrets
        name: secret-prometheus-k8s-proxy
      - mountPath: /etc/proxy/htpasswd
        name: secret-prometheus-k8s-htpasswd
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: prometheus-k8s-token-7fw4s
        readOnly: true
    - args:
      - --webhook-url=http://localhost:9090/-/reload
      - --volume-dir=/etc/prometheus/rules/prometheus-k8s-rulefiles-0
      image: quay.io/coreos/configmap-reload:v0.0.1
      imagePullPolicy: IfNotPresent
      name: rules-configmap-reloader
      resources:
        limits:
          cpu: 5m
          memory: 10Mi
        requests:
          cpu: 5m
          memory: 10Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
        name: prometheus-k8s-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: prometheus-k8s-token-7fw4s
        readOnly: true
    dnsPolicy: ClusterFirst
    hostname: prometheus-k8s-0
    imagePullSecrets:
    - name: prometheus-k8s-dockercfg-xvftr
    nodeName: infra1
    nodeSelector:
      node-role.kubernetes.io/infra: "true"
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000150000
      seLinuxOptions:
        level: s0:c12,c9
    serviceAccount: prometheus-k8s
    serviceAccountName: prometheus-k8s
    subdomain: prometheus-operated
    terminationGracePeriodSeconds: 600
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - name: prometheus-k8s-db
      persistentVolumeClaim:
        claimName: prometheus-k8s-db-prometheus-k8s-0
    - name: config
      secret:
        defaultMode: 420
        secretName: prometheus-k8s
    - emptyDir: {}
      name: config-out
    - configMap:
        defaultMode: 420
        name: prometheus-k8s-rulefiles-0
      name: prometheus-k8s-rulefiles-0
    - name: secret-prometheus-k8s-tls
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-tls
    - name: secret-prometheus-k8s-proxy
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-proxy
    - name: secret-prometheus-k8s-htpasswd
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-htpasswd
    - name: prometheus-k8s-token-7fw4s
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-token-7fw4s
  status:
    phase: Pending
    qosClass: Burstable
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: restricted
    creationTimestamp: null
    generateName: prometheus-k8s-
    labels:
      app: prometheus
      controller-revision-hash: prometheus-k8s-548c5f577d
      prometheus: k8s
      statefulset.kubernetes.io/pod-name: prometheus-k8s-1
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: prometheus-k8s
      uid: e9c51ffb-de8b-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - --web.console.templates=/etc/prometheus/consoles
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --config.file=/etc/prometheus/config_out/prometheus.env.yaml
      - --storage.tsdb.path=/prometheus
      - --storage.tsdb.retention=15d
      - --web.enable-lifecycle
      - --storage.tsdb.no-lockfile
      - --web.external-url=https://prometheus-k8s-openshift-monitoring.apps.5.9.163.226.xip.io/
      - --web.route-prefix=/
      - --web.listen-address=127.0.0.1:9090
      image: openshift/prometheus:v2.3.2
      imagePullPolicy: IfNotPresent
      name: prometheus
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/prometheus/config_out
        name: config-out
        readOnly: true
      - mountPath: /prometheus
        name: prometheus-k8s-db
        subPath: prometheus-db
      - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
        name: prometheus-k8s-rulefiles-0
      - mountPath: /etc/prometheus/secrets/prometheus-k8s-tls
        name: secret-prometheus-k8s-tls
        readOnly: true
      - mountPath: /etc/prometheus/secrets/prometheus-k8s-proxy
        name: secret-prometheus-k8s-proxy
        readOnly: true
      - mountPath: /etc/prometheus/secrets/prometheus-k8s-htpasswd
        name: secret-prometheus-k8s-htpasswd
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: prometheus-k8s-token-7fw4s
        readOnly: true
    - args:
      - --log-format=logfmt
      - --reload-url=http://localhost:9090/-/reload
      - --config-file=/etc/prometheus/config/prometheus.yaml
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      image: quay.io/coreos/prometheus-config-reloader:v0.23.2
      imagePullPolicy: IfNotPresent
      name: prometheus-config-reloader
      resources:
        limits:
          cpu: 10m
          memory: 50Mi
        requests:
          cpu: 10m
          memory: 50Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: prometheus-k8s-token-7fw4s
        readOnly: true
    - args:
      - -provider=openshift
      - -https-address=:9091
      - -http-address=
      - -email-domain=*
      - -upstream=http://localhost:9090
      - -htpasswd-file=/etc/proxy/htpasswd/auth
      - -openshift-service-account=prometheus-k8s
      - '-openshift-sar={"resource": "namespaces", "verb": "get"}'
      - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get"}}'
      - -tls-cert=/etc/tls/private/tls.crt
      - -tls-key=/etc/tls/private/tls.key
      - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
      - -cookie-secret-file=/etc/proxy/secrets/session_secret
      - -openshift-ca=/etc/pki/tls/cert.pem
      - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      - -skip-auth-regex=^/metrics
      image: openshift/oauth-proxy:v1.1.0
      imagePullPolicy: IfNotPresent
      name: prometheus-proxy
      ports:
      - containerPort: 9091
        name: web
        protocol: TCP
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-prometheus-k8s-tls
      - mountPath: /etc/proxy/secrets
        name: secret-prometheus-k8s-proxy
      - mountPath: /etc/proxy/htpasswd
        name: secret-prometheus-k8s-htpasswd
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: prometheus-k8s-token-7fw4s
        readOnly: true
    - args:
      - --webhook-url=http://localhost:9090/-/reload
      - --volume-dir=/etc/prometheus/rules/prometheus-k8s-rulefiles-0
      image: quay.io/coreos/configmap-reload:v0.0.1
      imagePullPolicy: IfNotPresent
      name: rules-configmap-reloader
      resources:
        limits:
          cpu: 5m
          memory: 10Mi
        requests:
          cpu: 5m
          memory: 10Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
        name: prometheus-k8s-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: prometheus-k8s-token-7fw4s
        readOnly: true
    dnsPolicy: ClusterFirst
    hostname: prometheus-k8s-1
    imagePullSecrets:
    - name: prometheus-k8s-dockercfg-xvftr
    nodeName: infra0
    nodeSelector:
      node-role.kubernetes.io/infra: "true"
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000150000
      seLinuxOptions:
        level: s0:c12,c9
    serviceAccount: prometheus-k8s
    serviceAccountName: prometheus-k8s
    subdomain: prometheus-operated
    terminationGracePeriodSeconds: 600
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - name: prometheus-k8s-db
      persistentVolumeClaim:
        claimName: prometheus-k8s-db-prometheus-k8s-1
    - name: config
      secret:
        defaultMode: 420
        secretName: prometheus-k8s
    - emptyDir: {}
      name: config-out
    - configMap:
        defaultMode: 420
        name: prometheus-k8s-rulefiles-0
      name: prometheus-k8s-rulefiles-0
    - name: secret-prometheus-k8s-tls
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-tls
    - name: secret-prometheus-k8s-proxy
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-proxy
    - name: secret-prometheus-k8s-htpasswd
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-htpasswd
    - name: prometheus-k8s-token-7fw4s
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-token-7fw4s
  status:
    phase: Pending
    qosClass: Burstable
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      openshift.io/scc: restricted
    creationTimestamp: null
    generateName: prometheus-operator-6644b8cd54-
    labels:
      k8s-app: prometheus-operator
      pod-template-hash: "2200647810"
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: prometheus-operator-6644b8cd54
      uid: cc12c7a3-de8b-11e8-8181-fa163eed49fb
  spec:
    containers:
    - args:
      - --kubelet-service=kube-system/kubelet
      - --logtostderr=true
      - --config-reloader-image=quay.io/coreos/configmap-reload:v0.0.1
      - --prometheus-config-reloader=quay.io/coreos/prometheus-config-reloader:v0.23.2
      - --namespace=openshift-monitoring
      image: quay.io/coreos/prometheus-operator:v0.23.2
      imagePullPolicy: IfNotPresent
      name: prometheus-operator
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000150000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: prometheus-operator-token-mptgb
        readOnly: true
    dnsPolicy: ClusterFirst
    imagePullSecrets:
    - name: prometheus-operator-dockercfg-ppvgf
    nodeName: infra1
    nodeSelector:
      node-role.kubernetes.io/infra: "true"
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000150000
      seLinuxOptions:
        level: s0:c12,c9
    serviceAccount: prometheus-operator
    serviceAccountName: prometheus-operator
    terminationGracePeriodSeconds: 30
    volumes:
    - name: prometheus-operator-token-mptgb
      secret:
        defaultMode: 420
        secretName: prometheus-operator-token-mptgb
  status:
    phase: Pending
    qosClass: BestEffort
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      service.alpha.openshift.io/serving-cert-secret-name: alertmanager-main-tls
      service.alpha.openshift.io/serving-cert-signed-by: openshift-service-serving-signer@1541154708
    creationTimestamp: null
    labels:
      alertmanager: main
    name: alertmanager-main
  spec:
    ports:
    - name: web
      port: 9094
      protocol: TCP
      targetPort: web
    selector:
      alertmanager: main
      app: alertmanager
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: null
    labels:
      operated-alertmanager: "true"
    name: alertmanager-operated
  spec:
    clusterIP: None
    ports:
    - name: web
      port: 9093
      protocol: TCP
      targetPort: 9093
    - name: mesh
      port: 6783
      protocol: TCP
      targetPort: 6783
    selector:
      app: alertmanager
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: null
    labels:
      app: cluster-monitoring-operator
    name: cluster-monitoring-operator
  spec:
    clusterIP: None
    ports:
    - name: http
      port: 8080
      protocol: TCP
      targetPort: http
    selector:
      app: cluster-monitoring-operator
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      service.alpha.openshift.io/serving-cert-secret-name: grafana-tls
      service.alpha.openshift.io/serving-cert-signed-by: openshift-service-serving-signer@1541154708
    creationTimestamp: null
    name: grafana
  spec:
    ports:
    - name: https
      port: 3000
      protocol: TCP
      targetPort: https
    selector:
      app: grafana
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      service.alpha.openshift.io/serving-cert-secret-name: kube-state-metrics-tls
      service.alpha.openshift.io/serving-cert-signed-by: openshift-service-serving-signer@1541154708
    creationTimestamp: null
    labels:
      k8s-app: kube-state-metrics
    name: kube-state-metrics
  spec:
    clusterIP: None
    ports:
    - name: https-main
      port: 8443
      protocol: TCP
      targetPort: https-main
    - name: https-self
      port: 9443
      protocol: TCP
      targetPort: https-self
    selector:
      app: kube-state-metrics
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      service.alpha.openshift.io/serving-cert-secret-name: node-exporter-tls
      service.alpha.openshift.io/serving-cert-signed-by: openshift-service-serving-signer@1541154708
    creationTimestamp: null
    labels:
      k8s-app: node-exporter
    name: node-exporter
  spec:
    clusterIP: None
    ports:
    - name: https
      port: 9100
      protocol: TCP
      targetPort: https
    selector:
      app: node-exporter
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      service.alpha.openshift.io/serving-cert-secret-name: prometheus-k8s-tls
      service.alpha.openshift.io/serving-cert-signed-by: openshift-service-serving-signer@1541154708
    creationTimestamp: null
    labels:
      prometheus: k8s
    name: prometheus-k8s
  spec:
    ports:
    - name: web
      port: 9091
      protocol: TCP
      targetPort: web
    selector:
      app: prometheus
      prometheus: k8s
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: null
    labels:
      operated-prometheus: "true"
    name: prometheus-operated
  spec:
    clusterIP: None
    ports:
    - name: web
      port: 9090
      protocol: TCP
      targetPort: web
    selector:
      app: prometheus
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: null
    labels:
      k8s-app: prometheus-operator
    name: prometheus-operator
  spec:
    clusterIP: None
    ports:
    - name: http
      port: 8080
      protocol: TCP
      targetPort: http
    selector:
      k8s-app: prometheus-operator
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
